{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to MLflow\n",
    "\n",
    "This notebook introduces the open-source library [MLflow](https://mlflow.org/), a popular ML lifecycle management framework built and mantained by Databricks.\n",
    "\n",
    "> **_NOTE:_**  You can use this tutorial interactively as a jupyter notebook by cloning this repo and installing it with \n",
    " `poetry install` and then launching the `README.ipynb` notebook.\n",
    "\n",
    "## MLflow's \"Hello world!\"\n",
    "\n",
    "The most basic functionality of MLflow covers experiment tracking. The MLflow Tracking component is an API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for later visualizing the results.\n",
    "\n",
    "> **_NOTE:_**  In this first part, we will use MLflow *locally* (its default setup), meaning that all metadata and artifacts are stored in your working directory (under `mlruns/`). In the second part, we will connect to the remote MLflow server available at MeteoSwiss.\n",
    "\n",
    "### Using the Tracking API\n",
    "\n",
    "The MLflow Tracking API lets you log metrics and artifacts (files) from your data science code and see a history of your runs. You can see it at work in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import random, randint\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(experiment_name=\"mlflow-tutorial\")\n",
    "\n",
    "mlflow.start_run(run_name=\"dummy-run\")\n",
    "\n",
    "mlflow.log_param(\"param1\", randint(0, 100))\n",
    "\n",
    "mlflow.log_metric(\"foo\", random())\n",
    "mlflow.log_metric(\"foo\", random() + 1)\n",
    "mlflow.log_metric(\"foo\", random() + 2)\n",
    "\n",
    "if not os.path.exists(\"outputs\"):\n",
    "    os.makedirs(\"outputs\")\n",
    "\n",
    "with open(\"outputs/test.txt\", \"w\") as f:\n",
    "    f.write(\"hello world!\")\n",
    "\n",
    "mlflow.log_artifacts(\"outputs\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the Tracking UI\n",
    "\n",
    "By default, wherever you run your program, the tracking API writes data into files into a local ./mlruns directory. You can then run MLflowâ€™s Tracking UI:\n",
    "\n",
    "```\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "and view it at http://localhost:5000."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an actual ML model\n",
    "\n",
    "Next, we will use scikit-learn to train a simple model on actual data and see how MLflow can easily integrate within our ML workflow.\n",
    "\n",
    "This time, we will take advantage of MLflow's [autologging](https://mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.autolog)\n",
    "capability, which automatically captures the most common metadata and artifacts (inlcuding the trained model) from our experiments. We will also use `mlflow.start_run()` as a python context manager, in order to scope each run within one code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Enable MLflow's autologging functionality\n",
    "mlflow.autolog()\n",
    "\n",
    "# Load the diabetes dataset (regression task)\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Train/test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    diabetes_X, diabetes_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=\"diabetes-lr\") as active_run:\n",
    "\n",
    "    # Model training/fit\n",
    "    # > metrics are logged automatically\n",
    "    # by leveraging sklearn's .get_params() method\n",
    "    lm = linear_model.LinearRegression()\n",
    "    lm.fit(X_train, y_train)\n",
    "\n",
    "    # Model evaluation\n",
    "    # > metrics are logged automatically\n",
    "    # in this case, the R2 score metric is computed, see\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score\n",
    "    y_test_pred = lm.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once trained and properly logged, we can at any time query metadata and artifacts from the MLflow experiment database using an instance of [MlflowClient](https://mlflow.org/docs/latest/python_api/mlflow.client.html?highlight=search_experiments#mlflow.client.MlflowClient), the client of an MLflow Tracking Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "experiment = client.search_experiments(filter_string=\"name = 'mlflow-tutorial'\")[0]\n",
    "runs = client.search_runs(experiment_ids=experiment.experiment_id)\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "artifact_uri = runs[0].info.artifact_uri\n",
    "artifact_path = Path(urlparse(artifact_uri).path)\n",
    "!ls -l {artifact_path / \"model\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, autologging of the sklearn model produced many files in `model/`. Among these, `MLmodel` is a metadata file that tells MLflow how to load the model. Another file, `model.pkl`, is a serialized version of the linear regression model that you trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {artifact_path / \"model\" / \"MLmodel\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the model and make new predictions, we can use MLflow's [pyfunc](https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html) module, which serves as a default model interface for MLflow Python models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "my_model = mlflow.pyfunc.load_model(artifact_path / \"model\")\n",
    "my_model.predict(np.random.uniform(0, 1, (1, 10)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can even use MLflow to [deploy](https://mlflow.org/docs/latest/models.html#deploy-mlflow-models) a local REST server that can serve predictions by using the dedicated [CLI](https://mlflow.org/docs/latest/cli.html#mlflow-models). We do that by spawning a new process with `subprocess.Popen()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "command = f\"mlflow models serve -m {artifact_path}/model -p 1234 --env-manager local\"\n",
    "print(f\"{command}\")\n",
    "mlflow_serve = subprocess.Popen(command.split(\" \"))\n",
    "\n",
    "# wait some time to allow the MLflow server to spin up...\n",
    "# note that this time might need to be considerably longer the first time\n",
    "# that your run it (since it needs to create the virtualenv)\n",
    "time.sleep(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The REST API defines 4 endpoints:\n",
    "- /ping used for health check\n",
    "- /health (same as /ping)\n",
    "- /version used for getting the mlflow version\n",
    "- /invocations used for scoring\n",
    "\n",
    "\n",
    "> **_NOTE:_**  If you are running this notebook in your lab-vm, make sure that 'localhost' is listed within your `no_proxy` environment variable before executing the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output should include \"localhost\" when running from the lab-vm\n",
    "os.getenv(\"no_proxy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "host = \"http://localhost:1234\"\n",
    "sample_input = {\n",
    "    \"dataframe_split\": {\n",
    "        \"columns\": [\n",
    "            \"age\",\n",
    "            \"sex\",\n",
    "            \"bmi\",\n",
    "            \"bp\",\n",
    "            \"s1\",\n",
    "            \"s2\",\n",
    "            \"s3\",\n",
    "            \"s4\",\n",
    "            \"s5\",\n",
    "            \"s6\",\n",
    "        ],\n",
    "        \"data\": [np.random.uniform(0, 1, (10)).tolist()],\n",
    "    }\n",
    "}\n",
    "response = requests.post(\n",
    "    url=f\"{host}/invocations\",\n",
    "    data=json.dumps(sample_input),\n",
    "    headers={\"Content-type\": \"application/json\"},\n",
    ")\n",
    "response_json = json.loads(response.text)\n",
    "print(response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the MLflow server after the prediction\n",
    "mlflow_serve.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You reached the end of the first part of this tutorial. \n",
    "Next, we will show you how to use the remote MLflow server available to all ML pratictioners at MeteoSwiss.\n",
    "\n",
    "# Remote MLflow server\n",
    "\n",
    "For our purpose, we will use the DEVT instance running on our internal OpenShift platform. \n",
    "The MLflow UI is reachable at https://servicedevt.meteoswiss.ch/mlstore/ from the internal network\n",
    "or https://hubdevt.meteoswiss.ch/mlstore/ if you are working in the lab-vm.\n",
    "\n",
    "Using the remote server instead of the local setup is really simple.\n",
    "You just need to set the remote server URI at the beginning of your code using `mlflow.set_tracking_uri()`.\n",
    "The rest of the code remains the exact same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"https://hubdevt.meteoswiss.ch/mlstore/\")\n",
    "\n",
    "mlflow.set_experiment(experiment_name=\"sandbox\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\", randint(0, 100))\n",
    "    mlflow.log_artifact(\"outputs/test.txt\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the README\n",
    "\n",
    "To build the markdown's version for GitLab, run the following command:\n",
    "\n",
    "```\n",
    "make clean & poetry run jupyter nbconvert --execute --to markdown README.ipynb\n",
    "```\n",
    "\n",
    "The associated figures are saved in the `README_files/` folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlflow-tutorial-_b4AqQps-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f41702fe46d2c9071a8f07b35271e746a7d2c2c2f18fc3b69a4dcd9bb14985c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
